### Mom Test Reflection (≈500 words)

Conducting three Mom Test–style interviews fundamentally reshaped how I think about this project. Initially, I believed the problem was that students and early-career professionals lacked “better budgeting tools.” However, applying Mom Test principles—focusing on past behavior, concrete examples, and listening more than pitching—revealed that the core issue was not tooling sophistication, but behavioral friction and lack of reflection.

The most important shift came from asking about specific past situations instead of hypothetical reactions to my idea. For example, rather than asking, “Would you use a simple expense tracking app?”, I asked participants to describe the last time they overspent and how they realized it. All three interviews surfaced similar behavioral patterns: delayed awareness, reactive realization, and no structured reflection afterward. This consistency across participants strengthened the validity of the problem statement. The issue is not that people lack access to financial data—they already have bank apps—but that they lack structured visibility and intentional review.

Interview 2 was particularly instructive. The participant had already tried a spreadsheet and abandoned it within two weeks. This directly informed the PRD’s emphasis on low-friction logging. If a motivated software developer cannot sustain manual tracking due to perceived tedium, the solution cannot depend on high-effort workflows. That insight led to prioritizing “quick expense logging” as a Must Have and deprioritizing advanced analytics in early versions.

Another valuable lesson was recognizing what participants did not say. None of them expressed a strong need for automated bank integration or investment tracking. My initial instinct was to consider API-based transaction imports, but the interviews did not validate that assumption. Instead, participants repeatedly emphasized simplicity and clarity. This directly influenced the “Out of Scope” section in the PRD, keeping the product focused and reducing MVP complexity.

One weakness in my interviews, however, was insufficient probing depth. While I captured concrete examples, I did not always ask follow-up questions to uncover emotional context or behavioral triggers. For example, when a participant mentioned overspending on dining out, I could have explored questions such as: What triggered those decisions? Was it social pressure, stress, convenience? How did they feel afterward? Deeper probing could have produced richer qualitative insights to strengthen the reflection feature design.

Additionally, I did not systematically trace each user story back to a specific interview participant. While the themes clearly emerged from conversations, I should have documented which insight originated from which participant. This would improve traceability and strengthen evidence-based justification in the PRD.

Overall, the Mom Test process prevented me from building a feature-heavy budgeting tool based on assumptions. Instead, it clarified that the real opportunity lies in addressing a reflection gap rather than a transaction-recording gap. The interviews validated the need for low-friction logging and visual summaries while highlighting behavior change as the core value proposition.

If I were to iterate, I would (1) conduct at least two additional interviews, (2) incorporate structured follow-up probing to uncover emotional drivers, and (3) explicitly map each user story to interview evidence. This would improve both research rigor and product focus.
